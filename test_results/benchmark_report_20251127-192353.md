# MCP Tool + LLM Comparison Report
*Generated: 2025-11-27 19:23:53*

## üèÜ Overall Rankings

| Rank | Combination | Quality | Total Cost | Total Time | Search Time | Gen Time | Halluc. |
|------|-------------|---------|------------|------------|-------------|----------|---------|
| 1 | **jina_claude** | 72.6 | $0.0144 | 9.71s | 0.57s | 9.14s | 0 |
| 2 | **tavily_claude** | 71.1 | $0.0192 | 7.15s | 0.37s | 6.78s | 0 |
| 3 | **tavily_gpt4** | 64.5 | $0.0187 | 4.70s | 0.34s | 4.36s | 0 |
| 4 | **jina_gpt4** | 56.3 | $0.0143 | 6.53s | 0.36s | 6.16s | 0 |

## üìä Detailed Metrics

### JINA_CLAUDE

**Quality Breakdown:**
- Average Overall Quality: 72.6/100
- Average Accuracy: 71.2/100
- Average Completeness: 63.4/100
- Average Clarity: 96.4/100
- Average Helpfulness: 70.8/100

**Performance:**
- Avg Search Latency: 0.57s
- Avg Generation Latency: 9.14s
- Avg Total Latency: 9.71s
- Fastest query: 5.51s
- Slowest query: 19.41s

**Cost:**
- Avg Search Cost: $0.0020/query
- Avg Generation Cost: $0.0124/query
- Avg Total Cost: $0.0144/query
- Total for 25 queries: $0.36

**Reliability:**
- Hallucinations: 0/25 (‚úÖ EXCELLENT)
- Avg tokens used: 1383/query

**Quality Distribution:**
- Excellent (80-100): 15 questions
- Good (60-79): 3 questions
- Fair (40-59): 1 questions
- Poor (0-39): 6 questions

**Top scoring questions:** q9 (100), q12 (100), q13 (100)
**Low scoring questions:** q5 (15), q6 (15), q15 (12)

### TAVILY_CLAUDE

**Quality Breakdown:**
- Average Overall Quality: 71.1/100
- Average Accuracy: 70.4/100
- Average Completeness: 61.2/100
- Average Clarity: 95.6/100
- Average Helpfulness: 68.2/100

**Performance:**
- Avg Search Latency: 0.37s
- Avg Generation Latency: 6.78s
- Avg Total Latency: 7.15s
- Fastest query: 3.53s
- Slowest query: 12.87s

**Cost:**
- Avg Search Cost: $0.0120/query
- Avg Generation Cost: $0.0072/query
- Avg Total Cost: $0.0192/query
- Total for 25 queries: $0.48

**Reliability:**
- Hallucinations: 0/25 (‚úÖ EXCELLENT)
- Avg tokens used: 797/query

**Quality Distribution:**
- Excellent (80-100): 13 questions
- Good (60-79): 3 questions
- Fair (40-59): 2 questions
- Poor (0-39): 7 questions

**Top scoring questions:** q8 (100), q12 (100), q14 (100)
**Low scoring questions:** q7 (17), q11 (16), q19 (15)

### TAVILY_GPT4

**Quality Breakdown:**
- Average Overall Quality: 64.5/100
- Average Accuracy: 62.6/100
- Average Completeness: 54.4/100
- Average Clarity: 92.8/100
- Average Helpfulness: 61.6/100

**Performance:**
- Avg Search Latency: 0.34s
- Avg Generation Latency: 4.36s
- Avg Total Latency: 4.70s
- Fastest query: 1.95s
- Slowest query: 13.06s

**Cost:**
- Avg Search Cost: $0.0120/query
- Avg Generation Cost: $0.0067/query
- Avg Total Cost: $0.0187/query
- Total for 25 queries: $0.47

**Reliability:**
- Hallucinations: 0/25 (‚úÖ EXCELLENT)
- Avg tokens used: 668/query

**Quality Distribution:**
- Excellent (80-100): 13 questions
- Good (60-79): 1 questions
- Fair (40-59): 2 questions
- Poor (0-39): 9 questions

**Top scoring questions:** q4 (100), q12 (100), q13 (100)
**Low scoring questions:** q11 (15), q17 (15), q20 (12)

### JINA_GPT4

**Quality Breakdown:**
- Average Overall Quality: 56.3/100
- Average Accuracy: 50.2/100
- Average Completeness: 46.4/100
- Average Clarity: 93.0/100
- Average Helpfulness: 55.6/100

**Performance:**
- Avg Search Latency: 0.36s
- Avg Generation Latency: 6.16s
- Avg Total Latency: 6.53s
- Fastest query: 2.35s
- Slowest query: 13.77s

**Cost:**
- Avg Search Cost: $0.0020/query
- Avg Generation Cost: $0.0123/query
- Avg Total Cost: $0.0143/query
- Total for 25 queries: $0.36

**Reliability:**
- Hallucinations: 0/25 (‚úÖ EXCELLENT)
- Avg tokens used: 1233/query

**Quality Distribution:**
- Excellent (80-100): 11 questions
- Good (60-79): 1 questions
- Fair (40-59): 1 questions
- Poor (0-39): 12 questions

**Top scoring questions:** q4 (100), q9 (100), q12 (100)
**Low scoring questions:** q25 (15), q6 (14), q17 (12)

## üìà Comparative Analysis

### Quality Comparison
- Highest quality: **jina_claude** (72.6)
- Most accurate: **jina_claude** (71.2)
- Most complete: **jina_claude** (63.4)
- Clearest answers: **jina_claude** (96.4)

### Speed Comparison
- Fastest search: **tavily_gpt4** (0.34s)
- Fastest generation: **tavily_gpt4** (4.36s)
- Fastest total: **tavily_gpt4** (4.70s)

### Cost Comparison
- Cheapest search: **jina_claude** ($0.0020)
- Cheapest generation: **tavily_gpt4** ($0.0067)
- Cheapest total: **jina_gpt4** ($0.0143)

### Reliability Comparison
- Zero hallucinations: **jina_claude, tavily_claude, tavily_gpt4, jina_gpt4**
- Most reliable: **jina_claude** (0 hallucinations)

## üéØ Recommendations

### üèÜ BEST OVERALL: JINA_CLAUDE
- Highest quality (72.6/100)
- Hallucinations: 0
- Cost: $0.0144/query
- Speed: 9.71s/query
- **Use when:** Quality and reliability matter most

### ‚ö° BEST FOR SPEED: TAVILY_GPT4
- Fastest total time (4.70s)
- Quality: 64.5/100
- **Use when:** Speed is critical, slight quality trade-off acceptable

### üí∞ BEST VALUE: JINA_GPT4
- Lowest cost ($0.0143/query)
- Quality: 56.3/100
- **Use when:** Budget-conscious but need decent quality

---
*Report generated by BizGenie AI Evaluation Framework*
